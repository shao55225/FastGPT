<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>基础教程 on FastGPT</title><link>https://doc.tryfastgpt.ai/docs/course/</link><description>Recent content in 基础教程 on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/docs/course/index.xml" rel="self" type="application/rss+xml"/><item><title>快速上手</title><link>https://doc.tryfastgpt.ai/docs/course/quick-start/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/quick-start/</guid><description>更多使用技巧，查看视屏教程
知识库 link开始前，请准备一份测试电子文档，WORD，PDF，TXT，excel，markdown 都可以，比如公司休假制度，不涉密的销售说辞，产品知识等等。
这里使用 FastGPT 中文 README 文件为例。
首先我们需要创建一个知识库。
知识库创建完之后我们需要上传一点内容。
上传内容这里有四种模式：
手动输入：手动输入问答对，是最精准的数据 QA 拆分：选择文本文件，让AI自动生成问答对 直接分段：选择文本文件，直接将其按分段进行处理 CSV 导入：批量导入问答对 这里，我们选择 QA 拆分，让 AI 自动生成问答，若问答质量不高，可以后期手动修改。
点击上传后我们需要等待数据处理完成，等到我们上传的文件状态为可用。
应用 link点击「应用」按钮来新建一个应用，这里有四个模板，我们选择「知识库 + 对话引导」。
应用创建后来再应用详情页找到「知识库」模块，把我们刚刚创建的知识库添加进去。
添加完知识库后记得点击「保存并预览」，这样我们的应用就和知识库关联起来了。
然后我们就可以愉快的开始聊天啦。</description></item><item><title>AI 相关参数配置说明</title><link>https://doc.tryfastgpt.ai/docs/course/ai_settings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/ai_settings/</guid><description>在 FastGPT 的 AI 对话模块中，有一个 AI 高级配置，里面包含了 AI 模型的参数配置，本文详细介绍这些配置的含义。
返回AI内容（高级编排特有） link这是一个开关，打开的时候，当 AI 对话模块运行时，会将其输出的内容返回到浏览器（API响应）；如果关闭，AI 输出的内容不会返回到浏览器，但是生成的内容仍可以通过【AI回复】进行输出。你可以将【AI回复】连接到其他模块中。
最大上下文 link代表模型最多容纳的文字数量。
函数调用 link支持函数调用的模型，在使用工具时更加准确。
温度 link越低回答越严谨，少废话（实测下来，感觉差别不大）
回复上限 link最大回复 token 数量。注意，是回复的Tokens！不是上下文 tokens。
系统提示词 link被放置在上下文数组的最前面，role 为 system，用于引导模型。
引用模板 &amp;amp; 引用提示词 link这两个参数与知识库问答场景相关，可以控制知识库相关的提示词。
AI 对话消息组成 link想使用明白这两个变量，首先要了解传递传递给 AI 模型的消息格式。它是一个数组，FastGPT 中这个数组的组成形式为：
[ 内置提示词（config.json 配置，一般为空） 系统提示词 （用户输入的提示词） 历史记录 问题（由引用提示词、引用模板和用户问题组成） ] 🍅
Tips: 可以通过点击上下文按键查看完整的上下文组成，便于调试。
引用模板和提示词设计 link简易模式已移除该功能，仅在工作流中可配置，可点击工作流中AI对话节点内，知识库引用旁边的setting icon进行配置。随着模型的增强，这部分功能将逐步弱化。
引用模板和引用提示词通常是成对出现，引用提示词依赖引用模板。
FastGPT 知识库采用 QA 对(不一定都是问答格式，仅代表两个变量)的格式存储，在转义成字符串时候会根据引用模板来进行格式化。知识库包含多个可用变量： q, a, sourceId（数据的ID）, index(第n个数据), source(数据的集合名、文件名)，score(距离得分，0-1) 可以通过 {{q}} {{a}} {{sourceId}} {{index}} {{source}} {{score}} 按需引入。下面一个模板例子：</description></item><item><title>Web 站点同步</title><link>https://doc.tryfastgpt.ai/docs/course/websync/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/websync/</guid><description>该功能目前仅向商业版用户开放。
什么是 Web 站点同步 linkWeb 站点同步利用爬虫的技术，可以通过一个入口网站，自动捕获同域名下的所有网站，目前最多支持200个子页面。出于合规与安全角度，FastGPT 仅支持静态站点的爬取，主要用于各个文档站点快速构建知识库。
Tips: 国内的媒体站点基本不可用，公众号、csdn、知乎等。可以通过终端发送curl请求检测是否为静态站点，例如：
curl https://doc.tryfastgpt.ai/docs/intro/ 如何使用 link1. 新建知识库，选择 Web 站点同步 link 2. 点击配置站点信息 link 3. 填写网址和选择器 link 好了， 现在点击开始同步，静等系统自动抓取网站信息即可。
创建应用，绑定知识库 link 选择器如何使用 link选择器是 HTML CSS JS 的产物，你可以通过选择器来定位到你需要抓取的具体内容，而不是整个站点。使用方式为：
首先打开浏览器调试面板（通常是 F12，或者【右键 - 检查】） link 输入对应元素的选择器 link菜鸟教程 css 选择器，具体选择器的使用方式可以参考菜鸟教程。
上图中，我们选中了一个区域，对应的是div标签，它有 data-prismjs-copy, data-prismjs-copy-success, data-prismjs-copy-error 三个属性，这里我们用到一个就够。所以选择器是： div[data-prismjs-copy]
除了属性选择器，常见的还有类和ID选择器。例如：
上图 class 里的是类名（可能包含多个类名，都是空格隔开的，选择一个即可），选择器可以为：.docs-content
多选择器使用 link在开头的演示中，我们对 FastGPT 文档是使用了多选择器的方式来选择，通过逗号隔开了两个选择器。
我们希望选中上图两个标签中的内容，此时就需要两组选择器。一组是：.docs-content .mb-0.d-flex，含义是 docs-content 类下同时包含 mb-0和d-flex 两个类的子元素；
另一组是.docs-content div[data-prismjs-copy]，含义是docs-content 类下包含data-prismjs-copy属性的div元素。
把两组选择器用逗号隔开即可：.docs-content .mb-0.d-flex, .docs-content div[data-prismjs-copy]</description></item><item><title>知识库基础原理介绍</title><link>https://doc.tryfastgpt.ai/docs/course/rag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/rag/</guid><description>RAG文档
1. 引言 link随着自然语言处理（NLP）技术的迅猛发展，生成式语言模型（如GPT、BART等）在多种文本生成任务中表现卓越，尤其在语言生成和上下文理解方面。然而，纯生成模型在处理事实类任务时存在一些固有的局限性。例如，由于这些模型依赖于固定的预训练数据，它们在回答需要最新或实时信息的问题时，可能会出现“编造”信息的现象，导致生成结果不准确或缺乏事实依据。此外，生成模型在面对长尾问题和复杂推理任务时，常因缺乏特定领域的外部知识支持而表现不佳，难以提供足够的深度和准确性。
与此同时，检索模型（Retriever）能够通过在海量文档中快速找到相关信息，解决事实查询的问题。然而，传统检索模型（如BM25）在面对模糊查询或跨域问题时，往往只能返回孤立的结果，无法生成连贯的自然语言回答。由于缺乏上下文推理能力，检索模型生成的答案通常不够连贯和完整。
为了解决这两类模型的不足，检索增强生成模型（Retrieval-Augmented Generation，RAG）应运而生。RAG通过结合生成模型和检索模型的优势，实时从外部知识库中获取相关信息，并将其融入生成任务中，确保生成的文本既具备上下文连贯性，又包含准确的知识。这种混合架构在智能问答、信息检索与推理、以及领域特定的内容生成等场景中表现尤为出色。
1.1 RAG的定义 linkRAG是一种将信息检索与生成模型相结合的混合架构。首先，检索器从外部知识库或文档集中获取与用户查询相关的内容片段；然后，生成器基于这些检索到的内容生成自然语言输出，确保生成的内容既信息丰富，又具备高度的相关性和准确性。
2. RAG模型的核心机制 linkRAG 模型由两个主要模块构成：检索器（Retriever）与生成器（Generator）。这两个模块相互配合，确保生成的文本既包含外部的相关知识，又具备自然流畅的语言表达。
2.1 检索器（Retriever） link检索器的主要任务是从一个外部知识库或文档集中获取与输入查询最相关的内容。在RAG中，常用的技术包括：
向量检索：如BERT向量等，它通过将文档和查询转化为向量空间中的表示，并使用相似度计算来进行匹配。向量检索的优势在于能够更好地捕捉语义相似性，而不仅仅是依赖于词汇匹配。 传统检索算法：如BM25，主要基于词频和逆文档频率（TF-IDF）的加权搜索模型来对文档进行排序和检索。BM25适用于处理较为简单的匹配任务，尤其是当查询和文档中的关键词有直接匹配时。 RAG中检索器的作用是为生成器提供一个上下文背景，使生成器能够基于这些检索到的文档片段生成更为相关的答案。
2.2 生成器（Generator） link生成器负责生成最终的自然语言输出。在RAG系统中，常用的生成器包括：
BART：BART是一种序列到序列的生成模型，专注于文本生成任务，可以通过不同层次的噪声处理来提升生成的质量 。 GPT系列：GPT是一个典型的预训练语言模型，擅长生成流畅自然的文本。它通过大规模数据训练，能够生成相对准确的回答，尤其在任务-生成任务中表现尤为突出 。 生成器在接收来自检索器的文档片段后，会利用这些片段作为上下文，并结合输入的查询，生成相关且自然的文本回答。这确保了模型的生成结果不仅仅基于已有的知识，还能够结合外部最新的信息。
2.3 RAG的工作流程 linkRAG模型的工作流程可以总结为以下几个步骤：
输入查询：用户输入问题，系统将其转化为向量表示。 文档检索：检索器从知识库中提取与查询最相关的文档片段，通常使用向量检索技术或BM25等传统技术进行。 生成答案：生成器接收检索器提供的片段，并基于这些片段生成自然语言答案。生成器不仅基于原始的用户查询，还会利用检索到的片段提供更加丰富、上下文相关的答案。 输出结果：生成的答案反馈给用户，这个过程确保了用户能够获得基于最新和相关信息的准确回答。 3. RAG模型的工作原理 link3.1 检索阶段 link在RAG模型中，用户的查询首先被转化为向量表示，然后在知识库中执行向量检索。通常，检索器采用诸如BERT等预训练模型生成查询和文档片段的向量表示，并通过相似度计算（如余弦相似度）匹配最相关的文档片段。RAG的检索器不仅仅依赖简单的关键词匹配，而是采用语义级别的向量表示，从而在面对复杂问题或模糊查询时，能够更加准确地找到相关知识。这一步骤对于最终生成的回答至关重要，因为检索的效率和质量直接决定了生成器可利用的上下文信息 。
3.2 生成阶段 link生成阶段是RAG模型的核心部分，生成器负责基于检索到的内容生成连贯且自然的文本回答。RAG中的生成器，如BART或GPT等模型，结合用户输入的查询和检索到的文档片段，生成更加精准且丰富的答案。与传统生成模型相比，RAG的生成器不仅能够生成语言流畅的回答，还可以根据外部知识库中的实际信息提供更具事实依据的内容，从而提高了生成的准确性 。
3.3 多轮交互与反馈机制 linkRAG模型在对话系统中能够有效支持多轮交互。每一轮的查询和生成结果会作为下一轮的输入，系统通过分析和学习用户的反馈，逐步优化后续查询的上下文。通过这种循环反馈机制，RAG能够更好地调整其检索和生成策略，使得在多轮对话中生成的答案越来越符合用户的期望。此外，多轮交互还增强了RAG在复杂对话场景中的适应性，使其能够处理跨多轮的知识整合和复杂推理 。
4. RAG的优势与局限 link4.1 优势 link 信息完整性：RAG 模型结合了检索与生成技术，使得生成的文本不仅语言自然流畅，还能够准确利用外部知识库提供的实时信息。这种方法能够显著提升生成任务的准确性，特别是在知识密集型场景下，如医疗问答或法律意见生成。通过从知识库中检索相关文档，RAG 模型避免了生成模型“编造”信息的风险，确保输出更具真实性 。 知识推理能力：RAG 能够利用大规模的外部知识库进行高效检索，并结合这些真实数据进行推理，生成基于事实的答案。相比传统生成模型，RAG 能处理更为复杂的任务，特别是涉及跨领域或跨文档的推理任务。例如，法律领域的复杂判例推理或金融领域的分析报告生成都可以通过RAG的推理能力得到优化 。 领域适应性强：RAG 具有良好的跨领域适应性，能够根据不同领域的知识库进行特定领域内的高效检索和生成。例如，在医疗、法律、金融等需要实时更新和高度准确性的领域，RAG 模型的表现优于仅依赖预训练的生成模型 。 4.2 局限 linkRAG（检索增强生成）模型通过结合检索器和生成器，实现了在多种任务中知识密集型内容生成的突破性进展。然而，尽管其具有较强的应用潜力和跨领域适应能力，但在实际应用中仍然面临着一些关键局限，限制了其在大规模系统中的部署和优化。以下是RAG模型的几个主要局限性：
4.2.1 检索器的依赖性与质量问题 linkRAG模型的性能很大程度上取决于检索器返回的文档质量。由于生成器主要依赖检索器提供的上下文信息，如果检索到的文档片段不相关、不准确，生成的文本可能出现偏差，甚至产生误导性的结果。尤其在多模糊查询或跨领域检索的情况下，检索器可能无法找到合适的片段，这将直接影响生成内容的连贯性和准确性。</description></item><item><title>知识库搜索方案和参数</title><link>https://doc.tryfastgpt.ai/docs/course/dataset_engine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/dataset_engine/</guid><description>理解向量 linkFastGPT 采用了 RAG 中的 Embedding 方案构建知识库，要使用好 FastGPT 需要简单的理解Embedding向量是如何工作的及其特点。
人类的文字、图片、视频等媒介是无法直接被计算机理解的，要想让计算机理解两段文字是否有相似性、相关性，通常需要将它们转成计算机可以理解的语言，向量是其中的一种方式。
向量可以简单理解为一个数字数组，两个向量之间可以通过数学公式得出一个距离，距离越小代表两个向量的相似度越大。从而映射到文字、图片、视频等媒介上，可以用来判断两个媒介之间的相似度。向量搜索便是利用了这个原理。
而由于文字是有多种类型，并且拥有成千上万种组合方式，因此在转成向量进行相似度匹配时，很难保障其精确性。在向量方案构建的知识库中，通常使用topk召回的方式，也就是查找前k个最相似的内容，丢给大模型去做更进一步的语义判断、逻辑推理和归纳总结，从而实现知识库问答。因此，在知识库问答中，向量搜索的环节是最为重要的。
影响向量搜索精度的因素非常多，主要包括：向量模型的质量、数据的质量（长度，完整性，多样性）、检索器的精度（速度与精度之间的取舍）。与数据质量对应的就是检索词的质量。
检索器的精度比较容易解决，向量模型的训练略复杂，因此数据和检索词质量优化成了一个重要的环节。
提高向量搜索精度的方法 link 更好分词分段：当一段话的结构和语义是完整的，并且是单一的，精度也会提高。因此，许多系统都会优化分词器，尽可能的保障每组数据的完整性。 精简index的内容，减少向量内容的长度：当index的内容更少，更准确时，检索精度自然会提高。但与此同时，会牺牲一定的检索范围，适合答案较为严格的场景。 丰富index的数量，可以为同一个chunk内容增加多组index。 优化检索词：在实际使用过程中，用户的问题通常是模糊的或是缺失的，并不一定是完整清晰的问题。因此优化用户的问题（检索词）很大程度上也可以提高精度。 微调向量模型：由于市面上直接使用的向量模型都是通用型模型，在特定领域的检索精度并不高，因此微调向量模型可以很大程度上提高专业领域的检索效果。 FastGPT 构建知识库方案 link数据存储结构 link在 FastGPT 中，整个知识库由库、集合和数据 3 部分组成。集合可以简单理解为一个文件。一个库中可以包含多个集合，一个集合中可以包含多组数据。最小的搜索单位是库，也就是说，知识库搜索时，是对整个库进行搜索，而集合仅是为了对数据进行分类管理，与搜索效果无关。（起码目前还是）
向量存储结构 linkFastGPT 采用了PostgresSQL的PG Vector插件作为向量检索器，索引为HNSW。且PostgresSQL仅用于向量检索（该引擎可以替换成其它数据库），MongoDB用于其他数据的存取。
在MongoDB的dataset.datas表中，会存储向量原数据的信息，同时有一个indexes字段，会记录其对应的向量ID，这是一个数组，也就是说，一组数据可以对应多个向量。
在PostgresSQL的表中，设置一个vector字段用于存储向量。在检索时，会先召回向量，再根据向量的ID，去MongoDB中寻找原数据内容，如果对应了同一组原数据，则进行合并，向量得分取最高得分。
多向量的目的和使用方式 link在一组向量中，内容的长度和语义的丰富度通常是矛盾的，无法兼得。因此，FastGPT 采用了多向量映射的方式，将一组数据映射到多组向量中，从而保障数据的完整性和语义的丰富度。
你可以为一组较长的文本，添加多组向量，从而在检索时，只要其中一组向量被检索到，该数据也将被召回。
意味着，你可以通过标注数据块的方式，不断提高数据块的精度。
检索方案 link 通过问题优化实现指代消除和问题扩展，从而增加连续对话的检索能力以及语义丰富度。 通过Concat query来增加Rerank连续对话的时，排序的准确性。 通过RRF合并方式，综合多个渠道的检索效果。 通过Rerank来二次排序，提高精度。 搜索参数 link 搜索模式 link语义检索 link语义检索是通过向量距离，计算用户问题与知识库内容的距离，从而得出“相似度”，当然这并不是语文上的相似度，而是数学上的。
优点：
相近语义理解 跨多语言理解（例如输入中文问题匹配英文知识点） 多模态理解（文本，图片，音视频等） 缺点：
依赖模型训练效果 精度不稳定 受关键词和句子完整度影响 全文检索 link采用传统的全文检索方式。适合查找关键的主谓语等。
混合检索 link同时使用向量检索和全文检索，并通过 RRF 公式进行两个搜索结果合并，一般情况下搜索结果会更加丰富准确。
由于混合检索后的查找范围很大，并且无法直接进行相似度过滤，通常需要进行利用重排模型进行一次结果重新排序，并利用重排的得分进行过滤。
结果重排 link利用ReRank模型对搜索结果进行重排，绝大多数情况下，可以有效提高搜索结果的准确率。不过，重排模型与问题的完整度（主谓语齐全）有一些关系，通常会先走问题优化后再进行搜索-重排。重排后可以得到一个0-1的得分，代表着搜索内容与问题的相关度，该分数通常比向量的得分更加精确，可以根据得分进行过滤。
FastGPT 会使用 RRF 对重排结果、向量搜索结果、全文检索结果进行合并，得到最终的搜索结果。</description></item><item><title>外部文件知识库</title><link>https://doc.tryfastgpt.ai/docs/course/externalfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/externalfile/</guid><description>外部文件库是 FastGPT 商业版特有功能。它允许接入你现在的文件系统，无需将文件再导入一份到 FastGPT 中。
并且，阅读权限可以通过你的文件系统进行控制。
导入参数说明 link 外部预览地址：用于跳转你的文件阅读地址，会携带“文件阅读ID”进行访问。 文件访问URL：文件可访问的地址。 文件阅读ID：通常情况下，文件访问URL是临时的。如果希望永久可以访问，你需要使用该文件阅读ID，并配合上“外部预览地址”，跳转至新的阅读地址进行原文件访问。 文件名：默认会自动解析文件访问URL上的文件名。如果你手动填写，将会以手动填写的值为准。 点击查看API导入文档</description></item><item><title>对话问题引导</title><link>https://doc.tryfastgpt.ai/docs/course/chat_input_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/chat_input_guide/</guid><description> 什么是自定义问题引导 link你可以为你的应用提前预设一些问题，用户在输入时，会根据输入的内容，动态搜索这些问题作为提示，从而引导用户更快的进行提问。
你可以直接在 FastGPT 中配置词库，或者提供自定义词库接口。
自定义词库接口 link需要保证这个接口可以被用户浏览器访问。
请求：
curl --location --request GET &amp;#39;http://localhost:3000/api/core/chat/inputGuide/query?appId=663c75302caf8315b1c00194&amp;amp;searchKey=你&amp;#39; 其中 appId 为应用ID，searchKey 为搜索关键字，最多是50个字符。
响应
{ &amp;#34;code&amp;#34;: 200, &amp;#34;statusText&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;data&amp;#34;: [ &amp;#34;是你&amp;#34;, &amp;#34;你是谁呀&amp;#34;, &amp;#34;你好好呀&amp;#34;, &amp;#34;你好呀&amp;#34;, &amp;#34;你是谁！&amp;#34;, &amp;#34;你好&amp;#34; ] } data是一个数组，包含了搜索到的问题，最多只需要返回5个问题。
参数说明：
appId - 应用ID searchKey - 搜索关键字</description></item><item><title>知识库集合标签</title><link>https://doc.tryfastgpt.ai/docs/course/collection_tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/collection_tags/</guid><description>知识库集合标签是 FastGPT 商业版特有功能。它允许你对知识库中的数据集合添加标签进行分类，更高效地管理知识库数据。
而进一步可以在问答中，搜索知识库时添加集合过滤，实现更精确的搜索。
标签基础操作说明 link在知识库详情页面，可以对标签进行管理，可执行的操作有
创建标签 修改标签名 删除标签 将一个标签赋给多个数据集合 给一个数据集合添加多个标签 也可以利用标签对数据集合进行筛选
知识库搜索-集合过滤说明 link利用标签可以在知识库搜索时，通过填写「集合过滤」这一栏来实现更精确的搜索，具体的填写示例如下
{ &amp;#34;tags&amp;#34;: { &amp;#34;$and&amp;#34;: [&amp;#34;标签 1&amp;#34;,&amp;#34;标签 2&amp;#34;], &amp;#34;$or&amp;#34;: [&amp;#34;有 $and 标签时，and 生效，or 不生效&amp;#34;] }, &amp;#34;createTime&amp;#34;: { &amp;#34;$gte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间大于该时间&amp;#34;, &amp;#34;$lte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间小于该时间,可和 $gte 共同使用&amp;#34; } } 在填写时有两个注意的点，
标签值可以为 string 类型的标签名，也可以为 null，而 null 代表着未设置标签的数据集合 标签过滤有 $and 和 $or 两种条件类型，在同时设置了 $and 和 $or 的情况下，只有 $and 会生效</description></item><item><title>文件输入功能介绍</title><link>https://doc.tryfastgpt.ai/docs/course/fileinput/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/fileinput/</guid><description>从 4.8.9 版本起，FastGPT 支持在简易模式和工作流中，配置用户上传文件、图片功能。下面先简单介绍下如何使用文件输入功能，最后是介绍下文件解析的工作原理。
简易模式中使用 link简易模式打开文件上传后，会使用工具调用模式，也就是由模型自行决策，是否需要读取文件内容。
可以找到左侧文件上传的配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
随后，你的调试对话框中，就会出现一个文件选择的 icon，可以点击文件选择 icon，选择你需要上传的文件。
由于采用的是工具调用模式，所以在提问时候，可能需要加上适当的引导，让模型知道，你需要读取文档。
工作流中使用 link工作流中，可以在系统配置中，找到文件输入配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
在工作流中，使用文件的方式很多，最简单的就是类似下图中，直接通过工具调用接入文档解析，实现和简易模式一样的效果。
也可以更简单点，强制每轮对话都携带上文档内容进行回答，这样就不需要调用两次 AI 才能读取文档内容了。
当然，你也可以在工作流中，对文档进行内容提取、内容分析等，然后将分析的结果传递给 HTTP 或者其他模块，从而实现文件处理的 SOP。不过目前版本，插件中并未支持文件处理，所以在构建 SOP 的话可能还是有一些麻烦。
文档解析工作原理 link不同于图片识别，LLM 模型目前没有支持直接解析文档的能力，所有的文档“理解”都是通过文档转文字后拼接 prompt 实现。这里通过几个 FAQ 来解释文档解析的工作原理，理解文档解析的原理，可以更好的在工作流中使用文档解析功能。
上传的文件如何存储在数据库中 linkFastGPT 的对话记录存储结构中，role=user 的消息，value 值会按以下结构存储：
type UserChatItemValueItemType = { type: &amp;#39;text&amp;#39; | &amp;#39;file&amp;#39; text?: { content: string; }; file?: { type: &amp;#39;img&amp;#39; | &amp;#39;doc&amp;#39; name?: string; url: string; }; }; 也就是说，上传的图片和文档，都会以 URL 的形式存储在库中，并不会存储解析后的文档内容。
图片如何处理 link文档解析节点不会处理图片，图片链接会被过滤，图片识别请直接使用支持图片识别的 LLM 模型。
文档解析节点如何工作 link文档解析依赖文档解析节点，这个节点会接收一个array&amp;lt;string&amp;gt;类型的输入，对应的是文件输入的 URL；输出的是一个string，对应的是文档解析后的内容。</description></item><item><title>接入飞书机器人教程</title><link>https://doc.tryfastgpt.ai/docs/course/feishu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/feishu/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入飞书机器人，无需额外的 API。
1. 申请飞书应用 link开一个免费的测试企业更方便进行调试。
在飞书开放平台的开发者后台申请企业自建应用。 添加一个机器人应用。
2. 在 FastGPT 新建发布渠道 link在fastgpt中选择想要接入的应用，在 发布渠道 页面，新建一个接入飞书机器人的发布渠道，填写好基础信息。
3. 获取应用的 App ID, App Secret 两个凭证 link在飞书开放平台开发者后台，刚刚创建的企业自建应用中，找到 App ID 和 App Secret，填入 FastGPT 新建发布渠道的对话框里面。
填入两个参数到 FastGPT 配置弹窗中。
（可选）在飞书开放平台开发者后台，点击事件与回调 -&amp;gt; 加密策略 获取 Encrypt Key，并填入飞书机器人接入的对话框里面
Encrypt Key 用于加密飞书服务器与 FastGPT 之间通信。 建议如果使用 Https 协议，则不需要 Encrypt Key。如果使用 Http 协议通信，则建议使用 Encrypt Key Verification Token 默认生成的这个 Token 用于校验来源。但我们使用飞书官方推荐的另一种更为安全的校验方式，因此可以忽略这个配置项。
4. 配置回调地址 link新建好发布渠道后，点击请求地址，复制对应的请求地址。
在飞书控制台，点击左侧的 事件与回调 ，点击配置订阅方式旁边的编辑 icon，粘贴刚刚复制的请求地址到输入框中。
5. 配置机器人回调事件和权限 link 添加 接收消息 事件 在事件与回调页面，点击添加事件。</description></item><item><title>通过 API 访问应用</title><link>https://doc.tryfastgpt.ai/docs/course/openapi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/openapi/</guid><description>在 FastGPT 中，你可以为每一个应用创建多个 API 密钥，用于访问应用的 API 接口。每个密钥仅能访问一个应用。完整的接口可以查看应用对话接口。
获取 API 密钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
🍅
Tips: 安全起见，你可以设置一个额度或者过期时间，放置 key 被滥用。
替换三方应用的变量 link OPENAI_API_BASE_URL: https://api.fastgpt.in/api (改成自己部署的域名) OPENAI_API_KEY = 上一步获取到的密钥 ChatGPT Next Web 示例：
ChatGPT Web 示例：</description></item><item><title>接入微信公众号教程</title><link>https://doc.tryfastgpt.ai/docs/course/official_account/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/course/official_account/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入微信公众号，无需额外的 API。
注意⚠️: 目前只支持通过验证的公众号（服务号和订阅号都可以）
1. 在 FastGPT 新建发布渠道 link在 FastGPT 中选择想要接入的应用，在 发布渠道 页面，新建一个接入微信公众号的发布渠道，填写好基础信息。
2. 登录微信公众平台，获取 AppID 、 Secret和Token link1. https://mp.weixin.qq.com 登录微信公众平台，选择您的公众号。 link只支持通过验证的公众号，未通过验证的公众号暂不支持。
开发者可以从这个链接申请微信公众号的测试号进行测试，测试号可以正常使用，但不能配置 AES Key
2. 把3个参数填入 FastGPT 配置弹窗中。 link 3. 在 IP 白名单中加入 FastGPT 的 IP link 私有部署的用户可自行查阅自己的 IP 地址。
海外版用户（cloud.tryfastgpt.ai)可以填写下面的 IP 白名单：
34.87.20.17 35.247.161.35 34.87.51.146 34.87.110.152 35.247.163.68 34.126.163.205 34.87.20.189 34.87.102.86 35.240.227.100 35.198.192.104 34.143.149.171 34.87.152.33 34.124.237.188 35.197.149.75 34.87.44.74 34.124.189.116 34.87.79.202 34.87.173.252 34.143.240.160 34.87.180.104 34.142.157.52 国内版用户（fastgpt.cn)可以填写下面的 IP 白名单：</description></item></channel></rss>